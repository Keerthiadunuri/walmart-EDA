{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01d22ac9",
   "metadata": {},
   "source": [
    "Task 1 â€” Data Loading, Merging & Initial Inspection\n",
    "Load all required CSV files into your notebook.\n",
    "Merge them into one dataset using Store, Dept, and Date.\n",
    "Display the first and last 10 rows.\n",
    "Print:\n",
    ".shape\n",
    ".info()\n",
    ".describe()\n",
    "Identify:\n",
    "Numerical columns\n",
    "Categorical columns\n",
    "Date columns\n",
    "List all unique store types and departments.\n",
    "7. Identify which columns may require cleaning or type conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47b6c147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FIRST 10 ROWS:\n",
      "   Store  Dept        Date  Weekly_Sales  IsHoliday_x  Temperature  \\\n",
      "0      1     1  2010-02-05      24924.50        False        42.31   \n",
      "1      1     1  2010-02-12      46039.49         True        38.51   \n",
      "2      1     1  2010-02-19      41595.55        False        39.93   \n",
      "3      1     1  2010-02-26      19403.54        False        46.63   \n",
      "4      1     1  2010-03-05      21827.90        False        46.50   \n",
      "5      1     1  2010-03-12      21043.39        False        57.79   \n",
      "6      1     1  2010-03-19      22136.64        False        54.58   \n",
      "7      1     1  2010-03-26      26229.21        False        51.45   \n",
      "8      1     1  2010-04-02      57258.43        False        62.27   \n",
      "9      1     1  2010-04-09      42960.91        False        65.86   \n",
      "\n",
      "   Fuel_Price  MarkDown1  MarkDown2  MarkDown3  MarkDown4  MarkDown5  \\\n",
      "0       2.572        NaN        NaN        NaN        NaN        NaN   \n",
      "1       2.548        NaN        NaN        NaN        NaN        NaN   \n",
      "2       2.514        NaN        NaN        NaN        NaN        NaN   \n",
      "3       2.561        NaN        NaN        NaN        NaN        NaN   \n",
      "4       2.625        NaN        NaN        NaN        NaN        NaN   \n",
      "5       2.667        NaN        NaN        NaN        NaN        NaN   \n",
      "6       2.720        NaN        NaN        NaN        NaN        NaN   \n",
      "7       2.732        NaN        NaN        NaN        NaN        NaN   \n",
      "8       2.719        NaN        NaN        NaN        NaN        NaN   \n",
      "9       2.770        NaN        NaN        NaN        NaN        NaN   \n",
      "\n",
      "          CPI  Unemployment  IsHoliday_y Type    Size  \n",
      "0  211.096358         8.106        False    A  151315  \n",
      "1  211.242170         8.106         True    A  151315  \n",
      "2  211.289143         8.106        False    A  151315  \n",
      "3  211.319643         8.106        False    A  151315  \n",
      "4  211.350143         8.106        False    A  151315  \n",
      "5  211.380643         8.106        False    A  151315  \n",
      "6  211.215635         8.106        False    A  151315  \n",
      "7  211.018042         8.106        False    A  151315  \n",
      "8  210.820450         7.808        False    A  151315  \n",
      "9  210.622857         7.808        False    A  151315  \n",
      "\n",
      "LAST 10 ROWS:\n",
      "        Store  Dept        Date  Weekly_Sales  IsHoliday_x  Temperature  \\\n",
      "421560     45    98  2012-08-24        415.40        False        72.62   \n",
      "421561     45    98  2012-08-31        346.04        False        75.09   \n",
      "421562     45    98  2012-09-07        352.44         True        75.70   \n",
      "421563     45    98  2012-09-14        605.96        False        67.87   \n",
      "421564     45    98  2012-09-21        467.30        False        65.32   \n",
      "421565     45    98  2012-09-28        508.37        False        64.88   \n",
      "421566     45    98  2012-10-05        628.10        False        64.89   \n",
      "421567     45    98  2012-10-12       1061.02        False        54.47   \n",
      "421568     45    98  2012-10-19        760.01        False        56.47   \n",
      "421569     45    98  2012-10-26       1076.80        False        58.85   \n",
      "\n",
      "        Fuel_Price  MarkDown1  MarkDown2  MarkDown3  MarkDown4  MarkDown5  \\\n",
      "421560       3.834    7936.20      58.38      22.00    5518.07    2291.97   \n",
      "421561       3.867   23641.30       6.00      92.93    6988.31    3992.13   \n",
      "421562       3.911   11024.45      12.80      52.63    1854.77    2055.70   \n",
      "421563       3.948   11407.95        NaN       4.30    3421.72    5268.92   \n",
      "421564       4.038    8452.20      92.28      63.24    2376.38    8670.40   \n",
      "421565       3.997    4556.61      20.64       1.50    1601.01    3288.25   \n",
      "421566       3.985    5046.74        NaN      18.82    2253.43    2340.01   \n",
      "421567       4.000    1956.28        NaN       7.89     599.32    3990.54   \n",
      "421568       3.969    2004.02        NaN       3.18     437.73    1537.49   \n",
      "421569       3.882    4018.91      58.08     100.00     211.94     858.33   \n",
      "\n",
      "               CPI  Unemployment  IsHoliday_y Type    Size  \n",
      "421560  191.344887         8.684        False    B  118221  \n",
      "421561  191.461281         8.684        False    B  118221  \n",
      "421562  191.577676         8.684         True    B  118221  \n",
      "421563  191.699850         8.684        False    B  118221  \n",
      "421564  191.856704         8.684        False    B  118221  \n",
      "421565  192.013558         8.684        False    B  118221  \n",
      "421566  192.170412         8.667        False    B  118221  \n",
      "421567  192.327265         8.667        False    B  118221  \n",
      "421568  192.330854         8.667        False    B  118221  \n",
      "421569  192.308899         8.667        False    B  118221  \n",
      "\n",
      "SHAPE (rows, columns):\n",
      "(421570, 17)\n",
      "\n",
      "INFO:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 421570 entries, 0 to 421569\n",
      "Data columns (total 17 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   Store         421570 non-null  int64  \n",
      " 1   Dept          421570 non-null  int64  \n",
      " 2   Date          421570 non-null  object \n",
      " 3   Weekly_Sales  421570 non-null  float64\n",
      " 4   IsHoliday_x   421570 non-null  bool   \n",
      " 5   Temperature   421570 non-null  float64\n",
      " 6   Fuel_Price    421570 non-null  float64\n",
      " 7   MarkDown1     150681 non-null  float64\n",
      " 8   MarkDown2     111248 non-null  float64\n",
      " 9   MarkDown3     137091 non-null  float64\n",
      " 10  MarkDown4     134967 non-null  float64\n",
      " 11  MarkDown5     151432 non-null  float64\n",
      " 12  CPI           421570 non-null  float64\n",
      " 13  Unemployment  421570 non-null  float64\n",
      " 14  IsHoliday_y   421570 non-null  bool   \n",
      " 15  Type          421570 non-null  object \n",
      " 16  Size          421570 non-null  int64  \n",
      "dtypes: bool(2), float64(10), int64(3), object(2)\n",
      "memory usage: 49.0+ MB\n",
      "None\n",
      "\n",
      "DESCRIPTIVE STATISTICS:\n",
      "               Store           Dept   Weekly_Sales    Temperature  \\\n",
      "count  421570.000000  421570.000000  421570.000000  421570.000000   \n",
      "mean       22.200546      44.260317   15981.258123      60.090059   \n",
      "std        12.785297      30.492054   22711.183519      18.447931   \n",
      "min         1.000000       1.000000   -4988.940000      -2.060000   \n",
      "25%        11.000000      18.000000    2079.650000      46.680000   \n",
      "50%        22.000000      37.000000    7612.030000      62.090000   \n",
      "75%        33.000000      74.000000   20205.852500      74.280000   \n",
      "max        45.000000      99.000000  693099.360000     100.140000   \n",
      "\n",
      "          Fuel_Price      MarkDown1      MarkDown2      MarkDown3  \\\n",
      "count  421570.000000  150681.000000  111248.000000  137091.000000   \n",
      "mean        3.361027    7246.420196    3334.628621    1439.421384   \n",
      "std         0.458515    8291.221345    9475.357325    9623.078290   \n",
      "min         2.472000       0.270000    -265.760000     -29.100000   \n",
      "25%         2.933000    2240.270000      41.600000       5.080000   \n",
      "50%         3.452000    5347.450000     192.000000      24.600000   \n",
      "75%         3.738000    9210.900000    1926.940000     103.990000   \n",
      "max         4.468000   88646.760000  104519.540000  141630.610000   \n",
      "\n",
      "           MarkDown4      MarkDown5            CPI   Unemployment  \\\n",
      "count  134967.000000  151432.000000  421570.000000  421570.000000   \n",
      "mean     3383.168256    4628.975079     171.201947       7.960289   \n",
      "std      6292.384031    5962.887455      39.159276       1.863296   \n",
      "min         0.220000     135.160000     126.064000       3.879000   \n",
      "25%       504.220000    1878.440000     132.022667       6.891000   \n",
      "50%      1481.310000    3359.450000     182.318780       7.866000   \n",
      "75%      3595.040000    5563.800000     212.416993       8.572000   \n",
      "max     67474.850000  108519.280000     227.232807      14.313000   \n",
      "\n",
      "                Size  \n",
      "count  421570.000000  \n",
      "mean   136727.915739  \n",
      "std     60980.583328  \n",
      "min     34875.000000  \n",
      "25%     93638.000000  \n",
      "50%    140167.000000  \n",
      "75%    202505.000000  \n",
      "max    219622.000000  \n",
      "\n",
      "NUMERICAL COLUMNS:\n",
      "['Store', 'Dept', 'Weekly_Sales', 'Temperature', 'Fuel_Price', 'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5', 'CPI', 'Unemployment', 'Size']\n",
      "\n",
      "CATEGORICAL COLUMNS:\n",
      "['Date', 'Type']\n",
      "\n",
      "DATE COLUMNS FOUND:\n",
      "['Date']\n",
      "\n",
      "UNIQUE STORE TYPES:\n",
      "['A' 'B' 'C']\n",
      "\n",
      "UNIQUE DEPARTMENTS:\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 16 17 18 19 20 21 22 23 24 25\n",
      " 26 27 28 29 30 31 32 33 34 35 36 37 38 40 41 42 44 45 46 47 48 49 51 52\n",
      " 54 55 56 58 59 60 67 71 72 74 77 78 79 80 81 82 83 85 87 90 91 92 93 94\n",
      " 95 96 97 98 99 39 50 43 65]\n",
      "\n",
      "COLUMNS THAT REQUIRE CLEANING (missing values):\n",
      "['MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5']\n",
      "\n",
      "COLUMNS WITH WRONG DATA TYPES:\n",
      "['Type']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  TASK 1 â€” DATA LOADING, MERGING & INITIAL INSPECTION\n",
    "\n",
    "import pandas as pd\n",
    "# 1. Load all required CSV files\n",
    "df_sales     = pd.read_csv(\"train.csv\")\n",
    "df_stores    = pd.read_csv(\"stores.csv\")\n",
    "df_features  = pd.read_csv(\"features.csv\")\n",
    "\n",
    "# 2. Merge datasets\n",
    "#     Merge on: Store, Dept, Date\n",
    "\n",
    "# First merge: sales + features\n",
    "df = pd.merge(df_sales, df_features, on=[\"Store\", \"Date\"], how=\"left\")\n",
    "\n",
    "# Second merge: add stores info\n",
    "df = pd.merge(df, df_stores, on=\"Store\", how=\"left\")\n",
    "\n",
    "# 3. Display first & last 10 rows\n",
    "print(\"\\nFIRST 10 ROWS:\")\n",
    "print(df.head(10))\n",
    "\n",
    "print(\"\\nLAST 10 ROWS:\")\n",
    "print(df.tail(10))\n",
    "\n",
    "# 4. Print shape, info, describe\n",
    "\n",
    "print(\"\\nSHAPE (rows, columns):\")\n",
    "print(df.shape)\n",
    "\n",
    "print(\"\\nINFO:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\nDESCRIPTIVE STATISTICS:\")\n",
    "print(df.describe())\n",
    "\n",
    "# 5. Identify numerical colum\n",
    "numerical_cols = df.select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "print(\"\\nNUMERICAL COLUMNS:\")\n",
    "print(numerical_cols)\n",
    "\n",
    "# 6. Identify categorical columns\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "print(\"\\nCATEGORICAL COLUMNS:\")\n",
    "print(categorical_cols)\n",
    "\n",
    "# 7. Identify date columns\n",
    "date_cols = [col for col in df.columns if 'date' in col.lower()]\n",
    "print(\"\\nDATE COLUMNS FOUND:\")\n",
    "print(date_cols)\n",
    "\n",
    "# Convert Date column to datetime (recommended)\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# 8. List unique Store Types & Departments\n",
    "\n",
    "\n",
    "# If store dataset has \"Type\" column\n",
    "if 'Type' in df.columns:\n",
    "    print(\"\\nUNIQUE STORE TYPES:\")\n",
    "    print(df['Type'].unique())\n",
    "\n",
    "# All unique departments\n",
    "if 'Dept' in df.columns:\n",
    "    print(\"\\nUNIQUE DEPARTMENTS:\")\n",
    "    print(df['Dept'].unique())\n",
    "\n",
    "# 9. Identify columns needing cleaning\n",
    "\n",
    "cleaning_required = []\n",
    "\n",
    "for col in df.columns:\n",
    "    if df[col].isnull().sum() > 0:\n",
    "        cleaning_required.append(col)\n",
    "\n",
    "print(\"\\nCOLUMNS THAT REQUIRE CLEANING (missing values):\")\n",
    "print(cleaning_required)\n",
    "\n",
    "print(\"\\nCOLUMNS WITH WRONG DATA TYPES:\")\n",
    "wrong_types = df.select_dtypes(include=['object']).columns.tolist()\n",
    "print(wrong_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a8092b",
   "metadata": {},
   "source": [
    "Task 2 â€” Data Cleaning\n",
    "Identify missing values using .isnull().sum().\n",
    "Fill missing numeric values (Temperature, Fuel_Price, CPI, Unemployment) using median.\n",
    "Fill missing markdown-related fields with mean values.\n",
    "Convert Date column to datetime format.\n",
    "Remove duplicate rows.\n",
    "Reset the index after cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf0fe158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      "Store                0\n",
      "Dept                 0\n",
      "Date                 0\n",
      "Weekly_Sales         0\n",
      "IsHoliday_x          0\n",
      "Temperature          0\n",
      "Fuel_Price           0\n",
      "MarkDown1       270889\n",
      "MarkDown2       310322\n",
      "MarkDown3       284479\n",
      "MarkDown4       286603\n",
      "MarkDown5       270138\n",
      "CPI                  0\n",
      "Unemployment         0\n",
      "IsHoliday_y          0\n",
      "Type                 0\n",
      "Size                 0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\welcome\\AppData\\Local\\Temp\\ipykernel_27928\\3962340747.py:16: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\welcome\\AppData\\Local\\Temp\\ipykernel_27928\\3962340747.py:16: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\welcome\\AppData\\Local\\Temp\\ipykernel_27928\\3962340747.py:16: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\welcome\\AppData\\Local\\Temp\\ipykernel_27928\\3962340747.py:16: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\welcome\\AppData\\Local\\Temp\\ipykernel_27928\\3962340747.py:24: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mean(), inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After Cleaning:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 421570 entries, 0 to 421569\n",
      "Data columns (total 17 columns):\n",
      " #   Column        Non-Null Count   Dtype         \n",
      "---  ------        --------------   -----         \n",
      " 0   Store         421570 non-null  int64         \n",
      " 1   Dept          421570 non-null  int64         \n",
      " 2   Date          421570 non-null  datetime64[ns]\n",
      " 3   Weekly_Sales  421570 non-null  float64       \n",
      " 4   IsHoliday_x   421570 non-null  bool          \n",
      " 5   Temperature   421570 non-null  float64       \n",
      " 6   Fuel_Price    421570 non-null  float64       \n",
      " 7   MarkDown1     421570 non-null  float64       \n",
      " 8   MarkDown2     421570 non-null  float64       \n",
      " 9   MarkDown3     421570 non-null  float64       \n",
      " 10  MarkDown4     421570 non-null  float64       \n",
      " 11  MarkDown5     421570 non-null  float64       \n",
      " 12  CPI           421570 non-null  float64       \n",
      " 13  Unemployment  421570 non-null  float64       \n",
      " 14  IsHoliday_y   421570 non-null  bool          \n",
      " 15  Type          421570 non-null  object        \n",
      " 16  Size          421570 non-null  int64         \n",
      "dtypes: bool(2), datetime64[ns](1), float64(10), int64(3), object(1)\n",
      "memory usage: 49.0+ MB\n",
      "None\n",
      "Store           0\n",
      "Dept            0\n",
      "Date            0\n",
      "Weekly_Sales    0\n",
      "IsHoliday_x     0\n",
      "Temperature     0\n",
      "Fuel_Price      0\n",
      "MarkDown1       0\n",
      "MarkDown2       0\n",
      "MarkDown3       0\n",
      "MarkDown4       0\n",
      "MarkDown5       0\n",
      "CPI             0\n",
      "Unemployment    0\n",
      "IsHoliday_y     0\n",
      "Type            0\n",
      "Size            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# TASK 2 â€” DATA CLEANINg-\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. Identify missing values\n",
    "print(\"Missing values in each column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# 2. Fill missing NUMERIC values with MEDIAN\n",
    "\n",
    "numeric_cols = ['Temperature', 'Fuel_Price', 'CPI', 'Unemployment']\n",
    "\n",
    "for col in numeric_cols:\n",
    "    if col in df.columns:\n",
    "        df[col].fillna(df[col].median(), inplace=True)\n",
    "\n",
    "\n",
    "# 3. Fill missing MARKDOWN values with MEAN\n",
    "\n",
    "markdown_cols = [col for col in df.columns if \"MarkDown\" in col or \"Markdown\" in col]\n",
    "\n",
    "for col in markdown_cols:\n",
    "    df[col].fillna(df[col].mean(), inplace=True)\n",
    "\n",
    "\n",
    "# 4. Convert Date column to datetime\n",
    "\n",
    "\n",
    "df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "\n",
    "# 5. Remove duplicate rows\n",
    "\n",
    "\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "\n",
    "# 6. Reset index\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "# FINAL CHECK\n",
    "\n",
    "\n",
    "print(\"\\nAfter Cleaning:\")\n",
    "print(df.info())\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d58604",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9095460f",
   "metadata": {},
   "source": [
    "Task 3 â€” Outlier Detection & Treatment\n",
    "Detect outliers in:\n",
    "Weekly_Sales\n",
    "Temperature\n",
    "Fuel_Price\n",
    "CPI\n",
    "Use:\n",
    "Boxplots\n",
    "IQR method\n",
    "Identify if extreme sales spikes occur during holiday weeks.\n",
    "Decide which outliers should be:\n",
    "Removed\n",
    "Capped\n",
    "Kept as business outliers\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4778e337",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#1.Distribution of Weekly Sales\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m5\u001b[39m))\n\u001b[0;32m      3\u001b[0m sns\u001b[38;5;241m.\u001b[39mhistplot(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWeekly_Sales\u001b[39m\u001b[38;5;124m'\u001b[39m], bins\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, kde\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDistribution of Weekly Sales\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# If Date is not converted yet\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# 1. Distribution of Weekly Sales\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.histplot(df['Weekly_Sales'], bins=50, kde=True)\n",
    "plt.title('Distribution of Weekly Sales')\n",
    "plt.xlabel('Weekly Sales')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# 2. Total Sales Over Time\n",
    "plt.figure(figsize=(12,6))\n",
    "df.groupby('Date')['Weekly_Sales'].sum().plot()\n",
    "plt.title('Total Weekly Sales Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Total Weekly Sales')\n",
    "plt.show()\n",
    "\n",
    "# 3. Sales by Store (Boxplot)\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.boxplot(x='Store', y='Weekly_Sales', data=df)\n",
    "plt.title('Weekly Sales by Store')\n",
    "plt.xlabel('Store')\n",
    "plt.ylabel('Weekly Sales')\n",
    "plt.show()\n",
    "\n",
    "# 4. Encode categorical columns for correlation\n",
    "df_corr = df.copy()\n",
    "categorical_cols = ['Type']  # Add more if needed\n",
    "\n",
    "for col in categorical_cols:\n",
    "    df_corr[col] = df_corr[col].astype('category').cat.codes\n",
    "\n",
    "# 5. Correlation Heatmap\n",
    "numeric_df = df_corr.select_dtypes(include=np.number)\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(numeric_df.corr(), annot=True, fmt='.2f', cmap='coolwarm')\n",
    "plt.title('Correlation Heatmap (Numeric + Encoded Categorical Features)')\n",
    "plt.show()\n",
    "\n",
    "# 6. Sales by Type\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.boxplot(x='Type', y='Weekly_Sales', data=df)\n",
    "plt.title('Weekly Sales by Store Type')\n",
    "plt.show()\n",
    "\n",
    "# 7. Sales vs Size\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.scatterplot(x='Size', y='Weekly_Sales', data=df)\n",
    "plt.title('Weekly Sales vs Store Size')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ca40e0",
   "metadata": {},
   "source": [
    "Task 4 â€” Univariate Analysis\n",
    "Perform univariate analysis (one variable at a time):\n",
    "Weekly sales distribution (Histogram + KDE).\n",
    "Store type distribution (Count plot).\n",
    "Distribution of Temperature, Fuel Price, CPI, Unemployment.\n",
    "Distribution of sales during:\n",
    "Holiday weeks\n",
    "Non-holiday weeks\n",
    "Identify top 10 departments by average weekly sales.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82015267",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f208206",
   "metadata": {},
   "source": [
    "âœ… Task 5 â€” Bivariate Analysis\n",
    "Study the relationship between two variables:\n",
    "Relationship between Temperature & Weekly Sales (scatter plot).\n",
    "Relationship between Fuel Price & Weekly Sales.\n",
    "Weekly Sales vs. Store Type.\n",
    "Weekly Sales vs. Holiday_Flag.\n",
    "Compare sales between:\n",
    "Top-performing store\n",
    "Lowest-performing store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49da2e78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a2becfb",
   "metadata": {},
   "source": [
    "\n",
    "âœ… Task 6 â€” Multivariate Analysis\n",
    "Analyze more than two variables together:\n",
    "Create a correlation heatmap for all numeric features.\n",
    "Analyze store-level sales using:\n",
    "Store Type\n",
    "Store Size\n",
    "Weekly Sales\n",
    "Multivariate relationship:\n",
    "Weekly Sales vs Temperature vs Holiday_Flag (3-variable plot or grouped summary)\n",
    "Analyze whether discount markdowns influence sales when considering:\n",
    "Date\n",
    "Holiday weeks\n",
    "Markdown values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ee8dab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5cb83bfe",
   "metadata": {},
   "source": [
    "âœ… Task 7 â€” Time Series Analysis\n",
    "Convert Date to:\n",
    "Year\n",
    "Month\n",
    "Week\n",
    "Plot total weekly sales over time.\n",
    "Plot monthly sales trends for:\n",
    "Store with highest sales\n",
    "Store with lowest sales\n",
    "Identify seasonal patterns:\n",
    "Which months show peak sales?\n",
    "Which departments show seasonal demand?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1cf62c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c747b531",
   "metadata": {},
   "source": [
    "\n",
    "ðŸ”¥ Task 8 â€” Feature Engineering\n",
    "Task 8A â€” Create New Columns\n",
    "year, month, week â†’ from date.\n",
    "discount_effect = MarkDown1 + MarkDown2 + MarkDown3 + MarkDown4 + MarkDown5\n",
    "is_peak_season â†’ True if month in {11, 12}.\n",
    "normalized_sales = Weekly_Sales / Size\n",
    "Task 8B â€” Filter Using Created Columns\n",
    "Show all peak-season transactions where weekly_sales > 50,000.\n",
    "Show all stores whose normalized_sales is in the top 10% percentile.\n",
    "Show departments where discount_effect > median discount.\n",
    "Filter rows where:\n",
    "Temperature < 40\n",
    "Fuel price > 3.5\n",
    "Weekly sales between 20,000 and 60,000\n",
    "is_peak_season = True\n",
    "Task 8C â€” Grouping & Business Insights\n",
    "Monthly average sales per store.\n",
    "Total discount_effect per department.\n",
    "Department with highest normalized_sales.\n",
    "Compute store-wise revenue potential:\n",
    "revenue_potential = Weekly_Sales * 52\n",
    "Identify top 10 stores based on revenue potential."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
